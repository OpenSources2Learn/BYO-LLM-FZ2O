| Title| Year |Paper|
| ------- | ----- | ------ |
|[Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling](https://arxiv.org/abs/2304.01373)|ICML2023|[[Paper]](https://arxiv.org/abs/2304.01373) ,[[Code]](https://github.com/EleutherAI/pythia?tab=readme-ov-file#pythia-interpreting-transformers-across-time-and-scale) ,[[Note]](https://mp.weixin.qq.com/s/2zdpbIeb7DzzEBY9kgGLuw)|
|[BloombergGPT: A Large Language Model for Finance](https://arxiv.org/abs/2303.17564)|Arxiv2023|[[Paper]](https://arxiv.org/abs/2303.17564)|
|[Orca 2: Teaching Small Language Models How to Reason](https://arxiv.org/abs/2311.11045)|Arxiv2023|[[Paper]](https://arxiv.org/abs/2311.11045)|
|[Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters](https://aclanthology.org/2023.acl-long.153.pdf)|Arxiv2023|[[Paper]](https://aclanthology.org/2023.acl-long.153.pdf) ,[[Note]](https://mp.weixin.qq.com/s/mi7rl8Wc2_RBsAKnvGSAzw)|
