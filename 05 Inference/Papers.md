| Title| Year |Paper|
| ------- | ----- | ------ |
|[LLM in a flash: Efficient Large Language Model Inference with Limited Memory](https://arxiv.org/pdf/2312.11514.pdf)|Arxiv2023|[[Paper]](https://arxiv.org/pdf/2312.11514.pdf)|
|[PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU](https://arxiv.org/pdf/2312.12456.pdf)|Arxiv2023|[[Paper]](https://arxiv.org/pdf/2312.12456.pdf)|
|[LASER](https://arxiv.org/abs/2312.13558)|Arxiv2023|[[Paper]](https://arxiv.org/abs/2312.13558) ,[[Note]](https://mp.weixin.qq.com/s/j17HExGEe6pgrgxlKYFvRw)|
|[Efficient Memory Management for Large Language Model Serving with PagedAttention](https://dl.acm.org/doi/abs/10.1145/3600006.3613165)|SOSP2023|[[Paper]](https://dl.acm.org/doi/abs/10.1145/3600006.3613165) ,[[Note]](https://mp.weixin.qq.com/s/NzD8Bf1wN9FeqY7HbatThw)|
|[RAG-Survey](https://arxiv.org/abs/2312.10997)|Arxiv2024|[[Paper]](https://arxiv.org/abs/2312.10997) ,[[Note]](https://mp.weixin.qq.com/s/oj5sf8CnEnbguVVVBEUHTA)|
|[When Do Program-of-Thought Works for Reasoning?](https://arxiv.org/pdf/2308.15452.pdf)|AAAI2024|[[Paper]](https://arxiv.org/pdf/2308.15452.pdf) ,[[Code]](https://github.com/zjunlp/EasyInstruct) ,[[Note]](https://mp.weixin.qq.com/s/5Qdhf2PYxdsjGZXq_bFCuw)|