| Title| Year |Paper|
| ------- | ----- | ------ |
|[LLM in a flash: Efficient Large Language Model Inference with Limited Memory](https://arxiv.org/pdf/2312.11514.pdf)|Arxiv2023|[[Paper]](https://arxiv.org/pdf/2312.11514.pdf)|
|[PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU](https://arxiv.org/pdf/2312.12456.pdf)|Arxiv2023|[[Paper]](https://arxiv.org/pdf/2312.12456.pdf)|