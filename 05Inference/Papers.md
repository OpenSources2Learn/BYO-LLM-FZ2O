| Title| Year |Paper|
| ------- | ----- | ------ |
|[LLM in a flash: Efficient Large Language Model Inference with Limited Memory](https://arxiv.org/pdf/2312.11514.pdf)|Arxiv2023|[[Paper]](https://arxiv.org/pdf/2312.11514.pdf)|
|[PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU](https://arxiv.org/pdf/2312.12456.pdf)|Arxiv2023|[[Paper]](https://arxiv.org/pdf/2312.12456.pdf)|
|[LASER](https://arxiv.org/abs/2312.13558)|Arxiv2023|[[Paper]](https://arxiv.org/abs/2312.13558) ,[[Note]](https://mp.weixin.qq.com/s/j17HExGEe6pgrgxlKYFvRw)|